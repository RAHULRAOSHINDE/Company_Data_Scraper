{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26568a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium.webdriver.edge.options import Options\n",
    "import time \n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time \n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6aa244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handles all driver related operations\n",
    "class WebDriverManager:\n",
    "     \n",
    "    def __init__(self):\n",
    "        self.driver = self._init_driver()\n",
    "\n",
    "    def _init_driver(self):\n",
    "        options = Options()\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        options.add_argument(\"--window-size=1920x1080\")\n",
    "        options.add_argument(\"--disable-javascript\")\n",
    "        driver = webdriver.Edge(options=options)\n",
    "        driver.implicitly_wait(5)\n",
    "        driver.delete_all_cookies()\n",
    "        driver.maximize_window() \n",
    "        return driver\n",
    "\n",
    "    def close_driver(self):\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9af25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the links to the company pages from the main listing page.\n",
    "class CompanyLinkScraper:\n",
    "\n",
    "    def __init__(self,driver):\n",
    "        self.driver = driver\n",
    "        self.company_url = \"https://yourstory.com/companies/search?page=1\"\n",
    "        self.company_links = set()\n",
    "       \n",
    "\n",
    "    # Extracts all company links from the listing page\n",
    "    def get_company_links(self):\n",
    "        self.driver.get(self.company_url)\n",
    "        self.driver.execute_script(\"window.scrollBy(0,500);\")\n",
    "\n",
    "        try:\n",
    "            company_table = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class='sc-68e2f78-2 eYOrlk'] table\"))\n",
    "            )\n",
    "            company_rows = company_table.find_elements(By.CSS_SELECTOR, 'tr')\n",
    "\n",
    "            for row in company_rows[1:]:\n",
    "                cells = row.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "                for cell in cells:\n",
    "                    link_element = cell.find_element(By.TAG_NAME, 'a')\n",
    "                    if link_element:\n",
    "                        link = link_element.get_attribute('href')\n",
    "                        self.company_links.add(link)\n",
    "        except TimeoutException:\n",
    "            print(\"Company table not found on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19141617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting data from each company page\n",
    "class CompanyDataScraper:\n",
    "    \n",
    "    def __init__(self, driver):\n",
    "        self.driver = driver\n",
    "               \n",
    "    #To extract text from elements\n",
    "    def get_text(self,parent, xpath):\n",
    "        try:\n",
    "            return parent.find_element(By.XPATH, xpath).text\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            return \"null\"\n",
    "        \n",
    "    # Extract data from an individual company page\n",
    "    def extract_company_data(self,company_links):\n",
    "        companies_data=[]\n",
    "        for company in company_links:\n",
    "            self.driver.get(company)\n",
    "            self.driver.implicitly_wait(5)\n",
    "            self.driver.execute_script(\"window.scrollBy(0,500);\")\n",
    "\n",
    "            try:\n",
    "                parent_element = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, 'sc-d93b8f6d-0'))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                parent_element = \"null\"\n",
    "                \n",
    "\n",
    "            company_data = {\n",
    "            \"Company Name\": self.get_text(self.driver, \".//div[contains(@class, 'sc-68e2f78-2') and .//span[text()='Legal Name']]//span[@class='sc-711bcf56-13 jlAcqN']\"),\n",
    "            \"Headquarters\": self.get_text(parent_element, \".//div[contains(@class, 'sc-68e2f78-2') and .//span[text()='Headquarters']]//following-sibling::div//span[@class='sc-711bcf56-13 jlAcqN']\"),\n",
    "            \"Business Model\":self.get_text(parent_element, \".//div[contains(@class, 'sc-68e2f78-2') and .//span[text()='Business Model']]//following-sibling::div//span[@class='sc-711bcf56-13 dppYfQ']\"),\n",
    "            \"Founding Date\":self.get_text(parent_element, \".//div[contains(@class, 'sc-68e2f78-2') and .//span[text()='Founding Date']]//following-sibling::div//span[@class='sc-711bcf56-13 jlAcqN']\"),\n",
    "            \"Number of Employees\":self.get_text(parent_element, \".//div[contains(@class, 'sc-68e2f78-2') and .//span[text()='No. of Employees']]//following-sibling::div//span[@class='sc-711bcf56-13 jlAcqN']\"),\n",
    "            \"Core Team / Founders\":self.extract_team_info()\n",
    "            }\n",
    "            companies_data.append(company_data)\n",
    "            \n",
    "        return companies_data\n",
    "            \n",
    "    def extract_team_info(self):\n",
    "        team_data=[]\n",
    "        team_members = self.driver.find_elements(By.XPATH, \"//div[contains(@class, 'sc-5bfa486-0')]\")\n",
    "        for member in team_members:\n",
    "            try:\n",
    "                name = member.find_element(By.XPATH, \".//div[contains(@class, 'sc-5bfa486-2')]//span[contains(@class, 'sc-711bcf56-13')]\").text    \n",
    "                try:\n",
    "                    linkedin_url = member.find_element(By.XPATH, \".//a[contains(@href, 'linkedin.com/in/')]\").get_attribute('href')\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    linkedin_url=\"null\"\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                name=\"null\"    \n",
    "            team_data.append(f'{name}:{linkedin_url}')\n",
    "        return ', '.join(team_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe66e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manages the storage of the scraped data and saves it to a csv file\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        self.companies_df = pd.DataFrame(columns=[\"Company Name\", \"Headquarters\", \"Business Model\", \"Founding Date\", \"Number of Employees\", \"Core Team / Founders\"])\n",
    "        \n",
    "    def store_data(self, company_data):\n",
    "        for data in company_data:\n",
    "            self.companies_df = pd.concat([self.companies_df, pd.DataFrame([data])], ignore_index=True)\n",
    "        self.companies_df.drop_duplicates(keep='first', inplace=True)\n",
    "        self.companies_df.replace(\"\", None, inplace=True)\n",
    "        \n",
    "    def save_to_csv(self, filename):\n",
    "        self.companies_df.to_csv(filename, index=False, na_rep='null')\n",
    "        print(f\"Data saved to {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Orchestrates the entire scraping process \n",
    "class CompanyScraperController:\n",
    "    def __init__(self):\n",
    "        self.driver_manager = WebDriverManager()\n",
    "        self.link_scraper = CompanyLinkScraper(self.driver_manager.driver)\n",
    "        self.data_scraper = CompanyDataScraper(self.driver_manager.driver)\n",
    "        self.data_store = DataStore()\n",
    "        \n",
    "    def start_scraping(self):\n",
    "        self.link_scraper.get_company_links()\n",
    "        company_data = self.data_scraper.extract_company_data(self.link_scraper.company_links)\n",
    "        self.data_store.store_data(company_data)\n",
    "        self.data_store.save_to_csv(\"company_scraper.csv\")\n",
    "        self.driver_manager.close_driver()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    scraper = CompanyScraperController()\n",
    "    scraper.start_scraping()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
